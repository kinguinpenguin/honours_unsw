%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  A small sample UNSW Honours Thesis file.
%  Any questions to Ian Doust i.doust@unsw.edu.au
%
% Edited CSG 11.9.2015, use some of Gery's ideas for front matter; add a conclusion chapter.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  The first part pulls in a UNSW Thesis class file.  This one is
%  slightly nonstandard and has been set up to do a couple of
%  things automatically
%
 
\documentclass[honours,12pt]{unswthesis}
\linespread{1}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{afterpage}
\usepackage{natbib}
\usepackage[colorlinks=true,citecolor=black,linkcolor=black,urlcolor=blue]{hyperref}
\usepackage[font=footnotesize,labelfont=bf]{caption}
\usepackage[export]{adjustbox}
\usepackage{lipsum}
\usepackage{mathrsfs}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  The following are some simple LaTeX macros to give some
%  commonly used letters in funny fonts. You may need more or less of
%  these
%
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\T}{\mathbb{T}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\B}{\mathfrak{B}}
\newcommand{\BB}{\mathcal{B}}
\newcommand{\M}{\mathfrak{M}}
\newcommand{\X}{\mathfrak{X}}
\newcommand{\Y}{\mathfrak{Y}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\ZZ}{\mathcal{Z}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% The following are much more esoteric commands that I have left in
% so that this file still processes. Use or delete as you see fit
%
\newcommand{\bv}[1]{\mbox{BV($#1$)}}
\newcommand{\comb}[2]{\left(\!\!\!\begin{array}{c}#1\\#2\end{array}\!\!\!\right)
}
\newcommand{\Lat}{{\rm Lat}}
\newcommand{\var}{\mathop{\rm var}}
\newcommand{\Pt}{{\mathcal P}}
\def\tr(#1){{\rm trace}(#1)}
\def\Exp(#1){{\mathbb E}(#1)}
\def\Exps(#1){{\mathbb E}\sparen(#1)}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\hatt}[1]{\widehat #1}
\newcommand{\modeq}[3]{#1 \equiv #2 \,(\text{mod}\, #3)}
\newcommand{\rmod}{\,\mathrm{mod}\,}
\newcommand{\p}{\hphantom{+}}
\newcommand{\vect}[1]{\mbox{\boldmath $ #1 $}}
\newcommand{\reff}[2]{\ref{#1}.\ref{#2}}
\newcommand{\psum}[2]{\sum_{#1}^{#2}\!\!\!'\,\,}
\newcommand{\bin}[2]{\left( \begin{array}{@{}c@{}}
				#1 \\ #2
			\end{array}\right)	}
%
%  Macros - some of these are in plain TeX (gasp!)
%
\newcommand{\be}{($\beta$)}
\newcommand{\eqp}{\mathrel{{=}_p}}
\newcommand{\ltp}{\mathrel{{\prec}_p}}
\newcommand{\lep}{\mathrel{{\preceq}_p}}
\def\brack#1{\left \{ #1 \right \}}
\def\bul{$\bullet$\ }
\def\cl{{\rm cl}}
\let\del=\partial
\def\enditem{\par\smallskip\noindent}
\def\implies{\Rightarrow}
\def\inpr#1,#2{\t \hbox{\langle #1 , #2 \rangle} \t}
\def\ip<#1,#2>{\langle #1,#2 \rangle}
\def\lp{\ell^p}
\def\maxb#1{\max \brack{#1}}
\def\minb#1{\min \brack{#1}}
\def\mod#1{\left \vert #1 \right \vert}
\def\norm#1{\left \Vert #1 \right \Vert}
\def\paren(#1){\left( #1 \right)}
\def\qed{\hfill \hbox{$\Box$} \smallskip}
\def\sbrack#1{\Bigl \{ #1 \Bigr \} }
\def\ssbrack#1{ \{ #1 \} }
\def\smod#1{\Bigl \vert #1 \Bigr \vert}
\def\smmod#1{\bigl \vert #1 \bigr \vert}
\def\ssmod#1{\vert #1 \vert}
\def\sspmod#1{\vert\, #1 \, \vert}
\def\snorm#1{\Bigl \Vert #1 \Bigr \Vert}
\def\ssnorm#1{\Vert #1 \Vert}
\def\sparen(#1){\Bigl ( #1 \Bigr )}

\newcommand\blankpage{%
    \null
    \thispagestyle{empty}%
    \addtocounter{page}{-1}%
    \newpage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% These environments allow you to get nice numbered headings
%  for your Theorems, Definitions etc.  
%
%  Environments
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{question}[theorem]{Question}
\newtheorem{notation}[theorem]{Notation}
\numberwithin{equation}{section}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  If you've got some funny special words that LaTeX might not
% hyphenate properly, you can give it a helping hand:
%
\hyphenation{Mar-cin-kie-wicz Rade-macher}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
% OK...Now we get to some actual input.  The first part sets up
% the title etc that will appear on the front page
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{ERGMs for Partially Ranked Data}

\authornameonly{Patrick Liang}

\author{\Authornameonly\\{\bigskip}Supervisor: Professor Pavel N. Krivitsky}

\copyrightfalse
\figurespagefalse
\tablespagefalse

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  And now the document begins
%  The \beforepreface and \afterpreface commands puts the
%  contents page etc in
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\beforepreface

\afterpage{\blankpage}

% plagiarism

\prefacesection{Plagiarism statement}

\vskip 10pc \noindent I declare that this thesis is my
own work, except where acknowledged, and has not been submitted for
academic credit elsewhere. 

\vskip 2pc  \noindent I acknowledge that the assessor of this
thesis may, for the purpose of assessing it:
\begin{itemize}
\item Reproduce it and provide a copy to another member of the University; and/or,
\item Communicate a copy of it to a plagiarism checking service (which may then retain a copy of it on its database for the purpose of future plagiarism checking).
\end{itemize}

\vskip 2pc \noindent I certify that I have read and understood the University Rules in
respect of Student Academic Misconduct, and am aware of any potential plagiarism penalties which may 
apply.\vspace{24pt}

\vskip 2pc \noindent By signing 
this declaration I am
agreeing to the statements and conditions above.
\vskip 2pc \noindent
Signed: \rule{7cm}{0.25pt} \hfill Date: \rule{4cm}{0.25pt} \newline
\vskip 1pc

\afterpage{\blankpage}

% Acknowledgements are optional


\prefacesection{Acknowledgements}

{\bigskip}By far the greatest thanks must go to my supervisor for
the guidance, care and support they provided. 

{\bigskip\noindent}Thanks 
must also go to Emily, Michelle, John and Alex who helped by
proof-reading the document in the final stages of preparation.

{\bigskip\noindent}Although
I have not lived with them for a number of years, my family also deserve
many thanks for their encouragement.

{\bigskip\noindent} Thanks go to Robert Taggart for allowing his thesis
style to be shamelessly copied.

{\bigskip\bigskip\bigskip\noindent} Patrick Liang, 2 November 2015.

\afterpage{\blankpage}

% Abstract

\prefacesection{Abstract}

To be added.
\afterpage{\blankpage}


\afterpreface

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Now we can start on the first chapter
% Within chapters we have sections, sections and so forth
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\afterpage{\blankpage}

\chapter{Exponential-Family Random Graph Models (ERGMs)}\label{s-intro}

Exponential-family random graph models (ERGMs) have become a central framework for modelling the structure of social networks. ERGMs are useful in that they can be specifically designed to capture the effects that variables have on the likelihood of certain patterns within a network. By representing the dependencies between individuals in a network, ERGMs enable the statistical analysis of network processes under a probabilistic framework. \hfill \break \hfill \break
This section introduces ERGMs, and reviews their applicability to rank-order relational data, as well as their uses for inference when modelling random graphs.
\section{ERGMs in Networks}
Networks are a representation of relational data, and show the interactions and connections between individuals. There are a variety of different networks which can be studied, from networks of social contacts, financial networks and collaboration networks, among others. As such, many researchers are interested in examining the factors which affect the structure of these networks, such as why some networks are densely interconnected and why others may be sparse \citep[p.~845]{vanDerPol2018}. \hfill \break \hfill \break
ERGMs are useful in the study of social networks, as for unknown links between individuals within a network, it allows the probability of a link between two nodes to be dependent on other links inside the network, amongst other variables, whilst also accounting for direct interactions and weighted interactions between nodes. \hfill \break \hfill \break Within the context of this project, ERGMs can be used on incomplete networks with missing or censored information, in order to model the possible variations of the missing links in the network, based on the known information and sample data. ERGMs can also be used for hypothesis testing, which opens up the possibility of analysing relational data as well as normal data \citep[p.~846]{vanDerPol2018}. \hfill \break \hfill \break 
Furthermore, \citet{vanDerPol2018} provides sample code to operationalise and interpret results and analyse goodness of fit, which can be used to trial and error ERGMs in RStudio to find which model maximises the likelihood. This can be helpful to ensure that the ERGM fitted is effective for in-depth analysis and to check for statistical significance.
\section{Degeneracy and Projectivity}
Using trial and error to test ERGMs is important to ensure that they are non-degenerate. Degeneracy generally refers to when ERGMs do not behave as expected during sampling and estimation \citep{mukherjee2020degeneracy}. Near-degenerate ERGMs tend to concentrate probability mass on a small set of extreme network configurations, such as almost empty or nearly complete networks. Concerns about the effects near-degeneracy and non-projectivity have on inference have been investigated in other works \citep[p.~632]{schweinberger2020exponential}.\hfill \break \hfill \break
Consider a subgraph $\textbf{y}_{\mathcal{N}'}$ of a population graph $\textbf{y}_{\mathcal{N}}$, induced by a subset of nodes $\mathcal{N}' \subset \mathcal{N}$. That is, $\textbf{y}_{\mathcal{N}'}$ is the subgraph with the set of nodes $\mathcal{N}'$ and all the edges among nodes in $\mathcal{N}'$ contained in the population graph $\textbf{y}_{\mathcal{N}}$. An ERGM is considered projective if:
\[\eta(\theta, \mathcal{N}') = \boldsymbol{\theta}~~\text{for all}~~\boldsymbol{\theta} \in \boldsymbol{\Theta}~~\text{and all}~~\mathcal{N}' \subseteq \mathcal{N},\]
and
\[\mathbb{P}_{\mathcal{N}',\boldsymbol{\theta}}(\textbf{Y}_{\mathcal{N}'} = \textbf{y}_{\mathcal{N}'}) = \mathbb{P}_{\mathcal{N},\boldsymbol{\theta}}(\textbf{Y}_{\mathcal{N}'} = \textbf{y}_{\mathcal{N}'}, \textbf{Y}_{\mathcal{N}\backslash \mathcal{N}'} \in \mathcal{Y}_{\mathcal{N}\backslash \mathcal{N}'}),\]
where $\textbf{Y}_{\mathcal{N}\backslash \mathcal{N}'} \in \mathcal{Y}_{\mathcal{N}\backslash \mathcal{N}'}$ denotes the subset of possible edges of the population graph not contained in $\textbf{y}_{\mathcal{N}}.$ That is, the same parameters govern the marginal distributions of all subgraphs of a larger network. \citet{schweinberger2020exponential} concludes that a lack of projectivity can affect non-likelihood-based inference, but is not necessary for likelihood-based-inference. As the analyses in this thesis rely primarily on likelihood-based estimation, projectivity is not a concern in this context.
\section{Population Inference Scenarios}
 For the data generating process, \citet{schweinberger2020exponential} defines three broad goals of statistical inference: finite, super and infinite population inference. Finite population inference is concerned with a finite population of nodes and a fixed population graph, super population inference is similar but assumes the population graph was generated by a population property model, and infinite population inference having an infinite population of nodes. \hfill \break \hfill \break They each have different goals: finite aims to estimate functions of the population graphs, such as the total number of edges in the population graph, super aims to estimate the population probability model which generates the possible population graphs, and the infinite aims to estimate the population probability model based on a subgraph induced by a subset of nodes. In all three of these scenarios, the consistency and asymptotic normality results for the likelihood-estimators confirmed that statistical inference for ERGMs is possible, but requires well-posed questions in order for the ERGMs to be well-behaved. \hfill \break \hfill \break In this project, we adopt the superpopulation inference framework, treating a given partially ranked network as a single draw from an underlying probabilistic model. Using ERGMs to perform maximum likelihood estimation (MLE) on the partial rankings, we generate parameter estimates of the underlying model.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Ranked Data and Statistical Methods}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Rank-order relational data, or ordinal relational data, is collected by having each actor in a network rank other actors according to some criterion, as defined by \citet{krivitsky2017exponential}. Rank-order data is notated by a set of $n$ actors, $N$ of which we index as $N = \{A, B, C, \ldots\}.$  Then, each actor $i$ denotes an ordinal relation $\succ_i$ over a set $N$. This relation can represent a multitude of things, such as ``preferred to" or ``interacted more with", and so on.
\section{Modelling Framework}
For two actors (egos) $i$ and $j,$ when asking them to rank some other actors (alters) $k$ and $l$, it's not meaningful to compare how either $i$ or $j$ ranks $k$, but it can be to ask whether $(k \succ_il) = (k \succ_jl).$ That is, ordinal relational data can be used to determine whether $i$ and $j's$ rankings of $k$ and $l$ are concordant, and can tell us something about the network. For example, if both $i$ and $j$ prefer $k$ over $l$, it could suggest that $l$ is less liked among the individuals in the network. The modelling framework utilised from \citet{krivitsky2017exponential} is founded on these distinctions.
\newpage
\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{Figures/ordinal_rank_structure.jpg}
\caption{A simple example of a ranking structure for ordinal relational data from \citet{krivitsky2017exponential}. Here, ego $\textbf{A}$'s rankings of alters $\textbf{B, C}$ and $\textbf{D}$ can be encoded as either a rank matrix by assigning arbitrary ranks of 1, 2 and 3 to $\textbf{B, C}$ and $\textbf{D}$ respectively, or instead as pairwise comparisons implied by $\textbf{A}.$ Note that $\Box$ denotes matrix entries that are unobservable and/or meaningless, such as people ranking themselves.}
\end{figure}
\hfill \break
Whilst ERGMs have been used to model internal network structures in a variety of contexts, they tend to pose some issues. When applied to dichotomised rank-order data, that is, the ordinal or ranked preferences have been converted into binary (yes/no, 0/1) ties, the model would inherit the difficulties that come with dichotomising, most notably losing information and introducing biases \citep{goodreau2009birds}. \hfill \break \hfill \break Building on the work of Robins et al. (1999), who was the first to model categorically network data using ERGMs, and Snijders (1996) who applied the stochastic actor-oriented framework to this data, \citet{krivitsky2012exponential} formulated a generalised framework for ERGMs on networks whose ties have values, as well as introducing Markov-chain Monte Carlo (MCMC) methods for simulation and maximum likelihood inference for this general framework. The paper also formulated the maximum likelihood inference for this general framework, which can be used to determine whether a fitted ERGM maximises the likelihood.
\hfill \break \hfill \break
\citet{krivitsky2017exponential} formally defined the sample space complete rankings of every actor in a network by every other actor as:
\[\mathscr{Y} = \left\{\boldsymbol{y}\prime\in \mathbb{S}^{\mathbb{Y}} : \forall_{i \in \mathbb{N}} \; \forall_{r \in \mathbb{S}}\exists \boldsymbol{!}_{j \in N \setminus \{i\}}\boldsymbol{y}\prime_{i,j} = r \right\}.\]
which is a directed network with no self-loops, whose set of observed relations $\mathbb{Y} = N^{2\neq}$ maps to dyad values $\mathbb{S} = \{1,..n - 1\}$. This also leads to the constraint that an ego must assign a unique rank to each possible alter.
\hfill \break  \hfill \break
The probability associated with each network $\boldsymbol{y} \in Y$ in the sample space is given by
\[\text{Pr}_{\boldsymbol{\theta}; g, \boldsymbol{x}}(\mathbf{Y} = \boldsymbol{y}) =
\frac{\exp\left\{ \boldsymbol{\theta} \cdot g(\boldsymbol{y}; \boldsymbol{x}) \right\}}{\kappa_{g, \boldsymbol{x}}(\boldsymbol{\theta})}, \quad \boldsymbol{y} \in \mathscr{Y}\]
with the normalising factor
\[\kappa_{g, \boldsymbol{x}}(\boldsymbol{\theta}) =
\sum_{\boldsymbol{y}\prime \in \mathscr{Y}} \exp\left\{ \boldsymbol{\theta} \cdot g(\boldsymbol{y}\prime; \boldsymbol{x}) \right\},\]
where the sufficient statistic  $\boldsymbol{g(y;x)}$ is a function of network $\boldsymbol{y} \in Y$ that may be also dependent on fixed and known covariates $\boldsymbol{x} \in \mathbb{X}$ \citep[Section 2.3]{krivitsky2017exponential}. The probability is used to define the probability distribution of networks under a given ERGM, and serve as the basis for model estimation (ERGM fitting) and checking goodness of fit. 
\section{Promotion Statistics}
Another important concept to discuss is the use of ``promotion" statistics, which in this context means to change statistics or scores within the data structure. For complete ordering data, an ego changing the ranking of one alter will change the ranking of at least one other alter, and an atomic change swaps the rankings of two adjacently ranked alters. 
\hfill \break \hfill \break
An atomic change is represented as the effect of having ego $i$ ``promote" a promotable alter $j \in \{k \in N : k \neq i~\wedge~y_{i, k} < n - 1\}$, which represents swapping $j$’s rank with that of the alter previously ranked immediately above $j$. Then, the promotion statistic is defined by \cite{krivitsky2017exponential} as
\[\Delta_{i,j}^{\nearrow} g(\boldsymbol{y}) \equiv g(\boldsymbol{y}^{{i:j\leftrightarrows} j^{+}}) - g(\boldsymbol{y}),\]
where $(\boldsymbol{y}^{{i:j\,\leftrightarrows}j^{+}})$ represents the network $\boldsymbol{y}$ with $i's$ ranking of $j$ and $j^+$, the actor previously ranked immediately above $j$ by $i$ \citep[Section 3.1]{krivitsky2017exponential}. That is, the promotion statistic is defined as the change in $g$ resulting from $i$ ``promoting" $j$ by exactly one rank.
\section{Rank-order Network Statistics}
We also introduce statistical measures used to analyze ranked network data, as their associated parameters provide insight into the underlying network structure. The primary measures considered are nonconformity, deference, and inconsistency.
\subsection{Nonconformity}Nonconformity is a measure of the departure from shared or expected ranks. An instance of nonconformity, for example, would be if most egos rank $\textbf{A}$ over $\textbf{B}$, but one ego ranks $\textbf{B}$ over $\textbf{A}$. A natural statistic to summarise the degree of ratings nonconformity is defined by \citet{krivitsky2017exponential} as
\[g_{GNC}(\boldsymbol{y}) = \sum_{(i, j ,k, l) \in N^{4 \neq}} y_{l:j \succ k}(1 - y_{i:j \succ k}).\]
The promotion statistic for nonconformity is also given by
\[\Delta_{i,j}^{\nearrow} g_{GNC}(\boldsymbol{y}) = 2 \sum_{l \in N \setminus \{i,j,j^+\}} (y_{l:j^+ \succ j} - y_{l:j \succ j^+}),\]
which is derived by observing that when $i$ promotes $j$ over $j^+$, the statistic is incremented by 2 every other ego $l$ who has $j^+$ ranked over $j$, and decremented by 2 for every $l$ who has $j$ ranked over $j^+.$
\hfill \break \hfill \break
\citep{krivitsky2017exponential} also defines the statistics for local nonconformity $g_{LNC},$ which unlike global nonconformity $g_{GNC}$, factors in that $i$ may be more likely to conform to those whom they rank highly over those whom they rank lower. The statistic for $g_{LNC}$ is given by
\[g_{LNC}(\boldsymbol{y}) = \sum_{(i, j, k, l) \in N^{4 \neq}} y_{i:l \succ j} y_{i:l \succ k}y_{l:j \succ k}(1 - y_{i:j \succ k}),\]
with atomic effects for this statistic given by
\begin{equation*}
    \begin{split}
        \Delta_{i,j}^{\nearrow} g_{LNC}(\boldsymbol{y}) &= \sum_{k \in N \setminus \{i,j,j^+\}} (y_{i:k\succ j^+} y_{k:j^+ \succ j} - y_{i:k \succ j^+} y_{k:j \succ j^+} \\
        &+ y_{k:i\succ j^+} y_{k:j^+ \succ j} - y_{k:i \succ j} y_{k:j \succ j^+} \\
        &+ y_{j:k \succ j^+}y_{i:j^+ \succ k} - y_{j^+ : k \succ j} y_{i:j \succ k}).
    \end{split}
\end{equation*}
\subsection{Deference}
Deference aversion is a measure of the tendency for an ego to not rank others highly if they do not reciprocate deference, that is, they rank them below others. An example of deference aversion would be if an ego $i$ does not rank $l$ above $j$, with $l$ ranking $i$ below $j$. \citet{krivitsky2017exponential} captures the notion of this statistic with the following:
\[g_D(\boldsymbol{y}) = \sum_{(i,j, l) \in N^{3 \neq}} y_{l:j\succ i} y_{i:l \succ j},\]
which is expected to be lower when deference aversion is present. The promotion statistic is defined as:
\[\Delta^{\nearrow}_{i,j} g_D(\boldsymbol{y}) = 2(y_{j^+ : i \succ j} + y_{j:j^+ \succ i} - 1),\]
and is similarly to nonconformity reliant on adjacent actors. This makes calculating the promotion statistics for either nonconformity or deference more computationally intensive, as it needs to know which indicators change in between the two actors being swapped. Ideally for the promotion statistics for global or local nonconformity and deference, the promotion statistic formula is changed so that it can minimise the number indicators that change. This would allow us to easily recalculate whenever an atomic change occurs, which would reduce computational costs for the network's data structure.
\subsection{Inconsistency}
Inconsistency in a given network is a measure of the tendency of each ego to rank alters discordantly. That is, whether an ego follows a trend to their alter rankings, as we expect that an ego will tend to exhibit consistency in alter ratings \citep{krivitsky2017exponential}. For example, if the general trend in the network is to rate the three alters $A, B$ and $C$ as $A \succ B \succ C$, if an ego $X$ ranks them as $A \succ C \succ B$, ego $X$ exhibits inconsistency. For two ranking structures $\boldsymbol{y}$ and $\boldsymbol{y} \prime$ on vertex sets $N$ and $N^{\prime}$ such that $N_s$ represents the actors involved in both networks, the statistic measuring inconsistency is given by
\[g_\text{I}(\boldsymbol{y};\boldsymbol{y} \prime) = \sum_{(i,j,k)\in N_s^{3\neq}} [\boldsymbol{y}_{i:j\succ k} (1 - \boldsymbol{y} \prime_{i:j \succ k}) + (1 - \boldsymbol{y}_{i:j \succ k}) \boldsymbol{y} \prime_{i:j \succ k}]\]
with promotion statistics
\[\Delta_{i,j}^{\nearrow} g_\text{I}(\boldsymbol{y};\boldsymbol{y} \prime) = 2(\boldsymbol{y} \prime_{i:j^+ \succ j} - \boldsymbol{y \prime}_{i:j \succ j^+})\]
Inconsistency tends to be sparse and difficult to capture, and is therefore less useful than deference and nonconformity for understanding a network’s underlying structure. For this reason, the analyses in this project will focus on deference and nonconformity as the parameters.
\section{The ``G-Method"}
The ``G-Method" is a generalized approach to assigning ranks in datasets where observations come from multiple groups or populations (``c" samples), include ordinal, non-numeric, or discrete variables and can also account for tied values.
\hfill \break \hfill \break
The ``G-Method” is a series of equations which form a mathematically formal rank assignment system, which systematically assigns ranks to observations in each of the ``c” samples after all the sample observations are pooled and assigned ranks \citep[Section 2]{oyeka2014gmethod}. These ``c” samples are defined as $x_{il}$, which are the $i^{th}$ observation or score in a random sample of size $n_l$ drawn from a population $x_l$, for $i$ = $1, 2, .., n$ and $l = 1, 2, \ldots c$. 
\hfill \break \hfill \break
This method is helpful dealing with rank-order relational data which may contain non-numeric ordinal entries, as the “G-Method” allows us to convert these into ranks for data analysis. Since ERGMs require valid rankings, the ``G-method" ensures that the input is well-formed before modelling for statistical analysis. For example, in Section 3, \citet{oyeka2014gmethod} demonstrates the use of the ``G-method" to convert letter grades into ranks for use in data analysis.
\section{Analysis Methods for Ranked Data}
Ranked response data, compared to other forms of statistical data, it is unique in that it is deterministic in nature, that is, the rank of the other items in the sample determine the rank of a certain item. 
\hfill \break \hfill \break \citet{finch2022introduction} provides applicable methodology to the use of libraries in R, as well as R code for the purposes of analysing ranking data, mainly through the statistical modelling of relative ranks, and inference regarding the difference in ranking patterns which may be noticeable between groups or samples.
\hfill \break \hfill \break 
An example of the latter is the analysis of fraternity data from \citet{alma9948926770001731}, which modelled the difference in ranking patterns in a group of fraternity students, as it changed over the course of 15 weeks of collected data.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Sampling, Privacy, and Representativeness}\label{cha}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

When dealing social networks, certain factors can affect the inference and consequently the conclusions drawn from a network. This section focuses on discussing how different methods of sampling and missing data can affect inference.
\section{Likelihood Inference}
Survey methods for gathering social network data tend to result in censored, missing or otherwise incomplete data. For example, the fixed rank nomination (FRN) scheme asks participants to nominate and rank a small number of contacts or friends, leaving other relations and their existence uncertain \citep{hoff2013likelihoods}. Problematically, statistical models tend to be formulated in terms of complete observed binary networks, meaning statistical analysis of FRN data with these kinds of models ignores the censored and ranked nature of the data, which can result in misleading statistical inference.
\hfill \break \hfill \break
Interestingly, when comparing Bayesian parameter estimates obtained from a likelihood for complete binary networks compared to likelihoods derived from the FRN scheme, they can draw different conclusions from the same data. Binary likelihood can provide misleading inference, especially for model parameters that relate network ties to characteristics of individuals and pairs of individuals \citep[p.~255]{hoff2013likelihoods}.
\hfill \break \hfill \break
It is important to not treat missing connections as non-existent, but instead censored, when simulating on partially ranked or incomplete data. We aim for an approach similar to the likelihoods derived from the FRN scheme, as we could treat partially ranked ordinal data as a form of data obtained from a FRN scheme, so that we do not make any assumptions about any of the missing data, and treat non-nominations instead as ranked and censored data instead, rather than absent. For example, we could assume a maximum nomination limit of $m$, and ties not nominated are treated as censored when the limit was reached, and as absent otherwise.
\hfill \break \hfill \break
Another important concept for modelling network data using ERGMs is the general convex hull problem. The convex hull of a finite set of points $S = \{p_1, p_2, \ldots, p_n\}$ in $\mathbb{R}^d$, denoted conv($S$), is the smallest convex set that contains all points in $S$. The general convex hull problem is useful when determining whether the estimator of the log-likelihood-ratio has a maximiser \citep{krivitsky2023likelihood}.
\hfill \break \hfill \break
\citet{krivitsky2012exponential} also discusses implementations in the widely used \texttt{ergm} package for network modeling, which improve the algorithm for the general convex hull problem algorithm. The general convex hull problem is helpful for calculating the log-likelihood ratio to assess the relative goodness of fit between two ERGMs applied to partially ranked data.
\hfill \break \hfill \break
It is important to consider the approach we should take when modelling social networks from sampled data. Most notably, inference for social networks assumes the presence or absence of all possible links is observed and the information is reliable with no measurement error. Naturally, this is not true in practice when it comes to network data collected through sampled surveys, and even if a census of a population is attempted, individuals and their links do not appear in the data.
\hfill \break \hfill \break
\citet{handcock2010modeling} suggests that likelihood-based inference from an adaptive network sample (a selection of additional nodes from a partially sampled network) can be conducted using a complete network model. However, it should be based on the available observed data, including the sampling design information. 
\hfill \break \hfill \break
That is, for a partially observed network $Y$, we can consider using the face-value likelihood based solely on $Y_{\text{obs}}$, which ignores additional information about $\eta$ available in $D$, where $\eta$ is the natural parameter and $D$ is the $n \times n$ random binary matrix indicating if the corresponding element of $Y$ was sampled or not \citep[Section~3.2]{handcock2010modeling}. 
Then, the inference for $\eta$ and $\psi$ should be based on all the available observed data only, and the likelihood is any function of $\eta$ and $\psi$ proportional to $P(D, Y_{\text{obs}}|\eta, \psi)$, where $\psi$ is the probability an individual gets selected at random from sampling.
\hfill \break \hfill \break
Such an approach gives some insight on a general likelihood framework for network inference for when the full network is not observed, and can be applied to partial rankings, as well as unobserved or unranked connections. Since partially ranked data isn’t random, it is crucial that we consider the sampling mechanism, so that we can base our likelihood inference on it. 
\section{Protecting the Privacy of Sampled Individuals}
When analysing synthetic networks, networks that mimic the statistical properties of a real social network, it is necessary to protect the privacy of individual relationships captured by the social network. A proposed approach to satisfy this would be a randomized response scheme for perturbing the edges and non-edges of the network, to generate a collection of synthetic edges whilst satisfying DP to control the risk \citep[Section~3.1]{karwa2017sharing}. The Differential Privacy (DP) framework is designed to capture the worst-case risk of releasing sensitive data \citep{dwork2006calibrating}. 
\hfill \break \hfill \break
Edge differential privacy (EDP) is a measure of the worst-case disclosure risk of identifying any relationship, which is represented by edges, between entities, represented by nodes \citep[Section~3.2]{karwa2017sharing}. To generate synthetic networks under $\epsilon$-edge differential privacy, \citet{karwa2017sharing} proposes a simple randomised response mechanism. For any two neighbouring networks $x$ and $x^{\prime}$, the EDP bounds the worst-case ratio of the likelihoods of $Y$ conditionally on $x$ and $x^{\prime}.$ That is, $P_{\gamma}(Y = y~|~X = x)$ is $\epsilon$-edge differentially private if and only if
\[
\max_{y} \max_{\substack{x, x': \Delta(x, x') = 1}} 
\log \left\{ \frac{P_{\gamma}(Y = y \mid X = x)}{P_{\gamma}(Y = y \mid X = x')} \right\} \leq \epsilon,
\]
where $P_\gamma(Y = y~|~X = x)$ denotes a family of conditional probability distributions, $x$ is the network that requires privacy protection, $Y$ is the random synthetic network obtained by sampling, and $\gamma$ is a vector parameter of the privacy mechanism controlling the generation of $Y$ from $x$. To find the maximum likelihood estimate (MLE) of $\boldsymbol{\theta}$, we apply the Monte Carlo maximum likelihood estimator \citep[Section~5]{karwa2017sharing}. The application and usefulness of these techniques are demonstrated in a case study using a version of the Enron e-mail corpus data set \citep{krivitsky2023tale}.
\hfill \break \hfill \break
These privacy-preserving methods are essential when dealing with sensitive social network data. However, this project focuses on simulation and methodological evaluation using publicly available datasets, and therefore privacy concerns are not a limiting factor.
\section{Generalisability of Network Sampling}
It would be helpful for our project to have a way to test whether a model is generalisable, that is, whether it can be applied to different datasets to simulate incomplete data. Generalisability is important as an indicator for whether a model for simulating incomplete data is overfitted.
\hfill \break \hfill \break
\citet{krivitsky2023tale} focuses on a case study between two samples of small networks of within-household contacts in Belgium, which were collected using two different but complementary sampling designs. The first sample was smaller, but with all contacts in each household observed, and the other sample is larger and more representative but recording contacts of only one person per household. 
\hfill \break \hfill \break
The paper aims to combine their strengths to learn the social forces that shape household contact formation. By doing so, it enables simulation for prediction of disease spread, while generalising to the population of households in the region. To accomplish this, they describe a flexible framework for specifying multi-network models in the ERGM class, and identify the requirements for inference and prediction under this framework to be consistent, identifiable and generalisable, for both complete or incomplete data. For each fitted model, they simulate multiple networks using estimated parameters and compare simulated network statistics to the observed ones.
We are most interested in the framework’s goal of evaluating model stability across structurally similar, but contextually different networks. 
\hfill \break \hfill \break
\citet{krivitsky2023tale} aims to find a model which is generalisable, that is, a model can be fitted to another dataset and can reproduce its structure, it is more generalisable. If a model fitted to dataset A poorly reproduces the data structure of dataset B, it signals that the model has limited generalisability. Their framework, whose implementation is published in the R package \texttt{ergm.multi}, is useful to determine whether a given ERGM can be applied to multiple datasets to simulate partial data.
\chapter{Optimising the Estimation of Ranked ERGMs}\label{cha}
Our main goal is, given an observed ranking, we want to be able to estimate the parameters of the underlying model which generated the network. The current version of \texttt{ergm.rank} supports Metropolis–Hastings proposals only for ERGMs with complete orderings. Our goal is to extend this functionality to accommodate partial orderings as well. Benchmarking figures and scripts used for testing \texttt{ergm.rank} can be found at \citet{ergmrank2025}.
\section{Dealing with
Computational Time Issues}
Ideally, we aim to model networks with up to 100 individuals. However, this proves to be a problem in time complexity, as the functions which consider how proposed changes to the network affect deference and local or global nonconformity, namely $\texttt{c\_deference}$, $\texttt{c\_nonconformity}$ and $\texttt{c\_localAND\_nonconformity}$ respectively, have significant computational run times. There are also some other functions which were changed, but these functions were the main issues, each with a time complexity of up to $\mathcal{O}(n^3).$
\hfill \break \hfill \break
In order to account for these issues, a new auxiliary structure was devised and created for each network structure. In the original functionality of $\texttt{ergm.rank},$ the only auxiliary structure was $\texttt{sm},$ which was a matrix of values which represented the rank each ego gave to an alter. For example, $\texttt{sm[i][j] = 4}$ means that the ego $i$ gave the alter $j$ a ranking of $4.$ As a result, when recalculating statistics such as deference and nonconformity, it would be necessary for $\texttt{ergm.rank}$ to iterate over every individual in a network.
\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{Figures/iterate_ego_closer.jpg}
\caption{When recalculating statistics such as deference and local or global nonconformity, $\texttt{ergm.rank}$ currently iterates over every alter $j$ for each ego $i$ in the network.}
\end{figure}
\hfill \break
The new auxiliary structure for implemented for $\texttt{ergm.rank}$, called $\texttt{udsm},$ is instead a matrix of structures which keep track of which alter is immediately above it and which alter is immediately below it.
\newpage
\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{Figures/struct_box_diagram up_down.jpg}
\caption{A visual representation of the struct created for \texttt{udsm}.}
\end{figure}
\hfill \break
For example, for an ego $i$ and an alter $j$, $\texttt{udsm[i][j].up = k}$ means that the alter $k$ is the individual ranked immediately above $j$ by $i$. Then, it becomes more cost efficient to iterate over the network, since it would only be necessary to iterate between two rankings when recalculating statistics, as evident in the formulas from Chapter 2. 
\hfill \break \hfill \break
Suppose we arbitrarily choose 2 points on a line uniformly. On average, the distance between these points would be a third of the length of the line. As such, it's expected that when iterating only between the old value which $i$ ranked $j$ and the new value that $i$ ranked $j$, the time complexity would be cut by two-thirds.
\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{Figures/udsm.pdf}
\caption{Consider an ego $i$ and their rankings of alters $a, b$ and $c.$ Then, if \texttt{sm[i][a]} were changed, using \texttt{udsm} we can start at the original value for \texttt{sm[i][a]} and iterate either up or down to the new value of \texttt{sm[i][a]}, allowing us to easily recalculate statistical measures without iterating over individuals who were not affected by the change.}
\end{figure}
\hfill \break
By tracking adjacently ranked alters, this auxiliary structure allows us to make use of promotion statistics (discussed in Chapter 2) when recalculating metrics such as deference and nonconformity. In turn, this enables the network's proposals to be re-designed as more efficient small-step proposal moves, so that $\texttt{ergm.rank}$ can be reasonably applied to larger networks without egregious computational times.
\section{Proposals}
ERGMs use Markov chain Monte Carlo (MCMC) in order to simulate networks from the model, as well as estimate the parameters by comparing simulated and observed statistics. This MCMC relies on proposals, which specify a mechanism for generating a small random change to the current network to explore the sample space.
\hfill \break \hfill \break
\citet{krivitsky2017exponential} uses a Metropolis-Hastings sampling algorithm (Algorithm A1) which chooses and ego at random, and makes a proposal to switch the ranking of two of its alters. The algorithm generates a series of networks through these small changes, accepting or rejecting each proposed network based on the current parameter estimates. These sampled networks are then used to estimate expected network statistics, which are compared to the observed statistics to update the parameter estimates. This process repeats iteratively until the parameter estimates converge, yielding the MLEs for the underlying probability model that generated the observed rankings. 
\hfill \break \hfill \break
Algorithm A1, however, is designed for sampling from a complete rank ERGM, which makes the assumption that each ego provides a complete, strict ordering of all alters in the network. As such, it is important for us to design an algorithm to propose changes to both a complete and a partially ranked network, as well as these changes being as small as possible for efficiency.
\hfill \break \hfill \break
A complete rank ERGM assumes that each ego provides a strict ordering of all alters with no ties and no omissions. Consequently, in the case of a complete ordering, the distribution of the orderings is that of a permutation of alters by the egos. As such, the smallest move we can make in a complete ordering is have an ego swap an adjacent pair of alters. At present, the current \texttt{ergm.rank} infrastructure implementation only has the \texttt{AlterSwap} proposal, which is applicable solely to ERGMs with complete orderings.
\hfill \break \hfill \break
Comparatively, a partially ranked ERGM is encoded to account for ties and missing rankings when generating a proposal. This is accomplished by giving each alter a rating from 1 to $n - 1$, where $n$ is the number of actors in the network, so that the distribution instead is the egos assigning repeatable values in that range to alters. The two proposals designed for partially ranked ERGMs in this project are \texttt{AdjacentAlterSwap} and \texttt{PartialDisc}. For this thesis, we have elected to use \texttt{AdjacentAlterSwap} for the purposes of testing of the proposed infrastructure and fitting partially ranked networks, but it is still worthwhile to distinguish between the two. As discussed in Section 3.1, the proposals will treat a partially ranked dataset as if it were completely ranked, effectively treating the missing data as censored rather than absent.
\hfill \break
\subsection{PartialDisc}
For \texttt{PartialDisc}, the smallest move we can make in a partial ordering is either incrementing or decrementing the rating of an alter by an ego. However, this implementation runs into a problem: what if we are currently looking at an alter rated $n - 1$ by an ego, or rated $1$? In that case, it would be impossible to increment up or down respectively. Consider a stationary distribution $p(y) 
\propto \exp(\eta \cdot g(y)) = \pi(y)$ for some parameter $\eta$ and $g(y)$ is a function of network $y \in Y$. Then, suppose we propose a change to the state of $y$, $y^* ~ q(\cdot | y^t).$ We denote the acceptance probability from the Metropolis-Hastings algorithm as:
\begin{equation*}
    \begin{split}
        \alpha &= \min\Bigg(1, \frac{\pi(y^*)}{\pi(y)} \times \frac{q(y | y^*)}{q(y^* | y)}\Bigg) \\
        \log(\alpha) &= \min\Bigg(\log 1, \log \frac{\pi(y^*)}{\pi(y)} + \log\frac{q(y | y^*)}{q(y^* | y)}\Bigg) \\
        &= \min\Bigg(0, \log \frac{\pi(y^*)}{\pi(y)} + \log\frac{q(y | y^*)}{q(y^* | y)}\Bigg) \\
        &= \min\Bigg(0, \log \frac{\exp(\eta \cdot g(y^*))}{\exp(\eta \cdot g(y))} + \log\frac{q(y | y^*)}{q(y^* | y)}\Bigg) \\
        &= \min\Bigg(0, \log \exp (\eta \cdot g(y^*) - \eta \cdot  g(y)) + \log\frac{q(y | y^*)}{q(y^* | y)}\Bigg) \\
        &= \min\Bigg(0, \eta \cdot (g(y^*) - g(y)) + \log\frac{q(y | y^*)}{q(y^* | y)}\Bigg)
    \end{split}
\end{equation*}
We accept the proposal if for $U \sim \text{Unif}(0, 1)$ we have $U \leq \alpha \Leftrightarrow \log U \leq \log \alpha.$
\[\log \frac{q(y | y^*)}{q(y^* | y)}\] is commonly referred to as the Hastings Ratio \citep{Holder2005-kh}. Introducing this term explicitly helps separate the effects of the network change, represented by the function \[\eta \cdot (g(y^*) - g(y)),\] and the proposal asymmetry. Note that $q(y^* | y)$ represents the probability of going from state $y$ to state $y^*$, and vice-versa for $q(y | y^*)$. 
\hfill \break \hfill \break
Now, consider the edge-state for an altar rated the maximum or minimum by an ego ($n$ and $1$ respectively). Because we can’t increment/decrement beyond the edges, the proposal distribution becomes asymmetric. So, the probability for $q(y | y^*)$ and $q(y^* | y)$ would not be the same, as for a proposed state $y^* = \text{max} - 1$, the probability of $q(y^* | y) = 1$, whereas the probability of $q(y | y^*) = 0.5$ since at $y^* = \text{max} - 1$ the edge-state can increment up or down.
\hfill \break \hfill \break
This is similarly the case for the minimum, $y = 1$, and so in both cases we have that \[\log \frac{q(y | y^*)}{q(y^* | y)} = \log \frac{0.5}{1} = \log \frac{1}{2}.\] Similarly, for the edge-states where an altar is rated one above the minimum or one below the maximum, the probability would be flipped, and we'd instead have
\[\log \frac{q(y | y^*)}{q(y^* | y)} = \log \frac{1}{0.5} = -\log \frac{1}{2}.\] For any other edge-state, the move probabilities are symmetric, so the proposal log-ratio is \[\log \frac{q(y | y^*)}{q(y^* | y)} = \log \frac{0.5}{0.5} = 0.\] That is, the log acceptance probability changes when an alter is ranked either on or next to the maximum or minimum by an ego, and has been accounted for in the proposal to swap adjacently ranked alters.
\subsection{AdjacentAlterSwap}
Comparatively, the \texttt{AdjacentAlterSwap} proposal is similar to the \texttt{PartialDisc} proposal, with the main difference being that the former always proposes "up" using the new auxiliary structure, and simply abandons the proposal if it happens to pick a node already at the top. This case occurs with probability $1/(n - 1)$ of the time, meaning it does not need adjustment as it only slightly hurts the efficiency of the proposal. As such, there is no edge cases which \texttt{AdjacentAlterSwap} needs to account for when considering the log acceptance probability, making it much simpler for the purposes of testing the infrastructure and fitting partial datasets for this project. 
\hfill \break \hfill \break
For future work, the \texttt{PartialDisc} proposal could be fully integrated into the R side of the package. Since the C implementation is already in place, this would allow us to evaluate its efficiency in practice and assess whether it provides advantages over \texttt{AdjacentAlterSwap}.
\chapter{Implementation and Evaluation using \texttt{ergm.rank}}
Using the new auxiliary structure, we apply the framework to larger networks to benchmark computational time. We also evaluate whether the redesigned proposal mechanism produces accurate MLE estimates on partially observed networks, compared to MLE estimates obtained from the full network.
\section{Dataset and Network Structure}
The Newcomb Fraternity Data \citep{Newcomb1961-yh} is a classic dataset used in social network and psychology research. Conducted by Theodore M. Newcomb at the University of Michigan, it was focused on exploring how individuals' preferences and social interactions evolve in a new group setting over time.
\hfill \break \hfill \break
The dataset consists of fifteen, \(17 \times 17\) matrices which recorded the sociometric preference rankings from 17 men across 15 weeks. Each week, participants would rank the other 16 men from best friend, down to least friend. Due to its small and fully observed nature, the Newcomb dataset has been widely studied, and in this project serves as a benchmark for testing the time complexity and accuracy of fitted missing data MLEs using the newly implemented infrastructure for $\texttt{ergm.rank}.$ Note that week 9 is missing, as participants were not present for that week.
\section{Implementation}
For this project, a script was written to perform the benchmarking experiments for evaluating the proposed auxiliary structure in the \texttt{ergm.rank} framework. The benchmarking scripts were implemented in R, and to assess the efficiency and accuracy of model fitting, for both complete and missing datasets.
\subsection{Model Fitting}
The benchmarking process takes the Newcomb dataset and generates a modified version containing missing data. In the first benchmark script, all rankings outside of the top five were replaced with NA to imitate a missing dataset. Two models are then fitted for each of the fifteen weeks in the dataset to estimate the parameters:
\hfill \break
\begin{itemize}
    \item[\textbf{1.}] \textbf{Complete data MLE:} The maximum likelihood estimate (MLE) using the fully observed rankings
    \item[\textbf{2.}] \textbf{Missing data MLE:} The MLE fitted using the partially observed dataset.
\end{itemize}
\hfill \break
For the missing data model, it is assumed that there exists a complete ordering beneath the observed partial ordering, so that the \texttt{AdjacentAlterSwap} proposal can be used. The fitted MLEs for each week are stored in an indexed list.
\hfill \break
\subsection{Evaluation Metrics}
A set of utility functions are used to extract and compare key model statistics between the complete data and missing data fits. For each week, the script computes and stores:
\hfill \break
\begin{itemize}
    \item[$\bullet$] Coefficients: $\texttt{(coef())}$
    \item[$\bullet$] Standard errors: $\texttt{(sqrt(diag(vcov())))}$
    \item[$\bullet$] Log-likelihood at the MLE: $\texttt{(logLik())}$
\end{itemize}
\vspace{0.5em}
\subsection{Timing and Output}
The total runtime is computed and written to a file alongside model results. The scripts also generate visual comparisons of the evaluation metrics computed across the fifteen weeks, allowing for direct comparison between the results from the complete data MLE and missing data MLE.
\hfill \break \hfill \break
\section{Computational Results and Analysis of \citet{Newcomb1961-yh}}
Having established the benchmarking framework and described the model-fitting procedure, we run the benchmarking scripts and obtain the evaluation metrics from the missing data and complete data MLEs, visually represented through the presented figures.
\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{Benchmarks/coef_trajectories_stacked.png}
\caption{Parameter estimates over time for deference, global nonconformity and local+global nonconformity, where error bars indicate $\pm$1 standard error. Note that Week 9 is missing as no rankings were recorded.}
\end{figure}
\hfill \break
\subsection{Deference}
For the \citep{Newcomb1961-yh} dataset, we see that parameter estimates of deference for both the constrained data MLE and the complete data MLE are negative throughout the entire fifteen weeks. This suggests that deference is disfavoured by the model, meaning the model would generate networks where deference is less prevalent compared to a network generated by ranking randomly. That is, there may not be a deferential structure, where people reciprocate when others rank them highly, and instead a structure that results in a competitive tendency between individuals in the network. We also generally see that the parameter estimates for deference generally trends downwards as the weeks progress, implying the network strayed further from a deferential structure as time passed.
\hfill \break \hfill \break
The parameter estimates for the constrained model are within one standard error of those from the true model, indicating that little information was lost by restricting the data to the top five rankings. Interestingly, the constrained model yields more negative parameter estimates, suggesting that even less deference is captured when by the top 5 rankings. That is, an individual's top choices appear to be driven less by deference and more by other factors such as personal preference or affinity.
\newpage
\subsection{Global Nonconformity}
The parameter estimates for global nonconformity under the complete-data MLE generally stay close to 0 throughout the time period, indicating that the level of global nonconformity in networks generated from the fitted model is not noticeably different from that expected under a random baseline. Note that the most negative parameter estimate occurs in the first week, likely reflecting the influence of initial impressions formed before participants had established any friendships. In the context of the \citep{Newcomb1961-yh} dataset, the results imply that participants’ rankings of others evolved largely independently, without contradicting any general consensus that may have formed within the group. 
\hfill \break \hfill \break
Comparatively, for the fitted MLE using only the top-five rankings, the parameter estimates for global nonconformity show similar values to the true model, but trend slightly below it as the weeks progress. This suggests that in the early weeks, there was limited agreement among individuals regarding whom they ranked in their top five, which follows as social circles and friendships had not yet been formed. However, as time went on, individuals appeared to reach more of an agreement about whom they considered their top five friends compared to others in the group. Very little information was lost by restricting the data to the top-five rankings, even when compared to the deference parameter, as the estimates between the two models lie within half a standard error of each other for a majority of the weeks. 
\subsection{Global and Local Nonconformity}
Interestingly, we see the biggest discrepancy between the parameter estimates for the complete and top 5 model when we consider both global and local nonconformity. Most notably, from week 6 onwards, we see that the parameter estimates for the top 5 model are noticeably higher than compared to the parameter estimates using the complete data. We recall that local nonconformity factors in that egos may be more likely to conform to those whom they rank highly, over those whom they rank lower.
\hfill \break \hfill \break
Then, this difference could be explained by the fact that local nonconformity cannot be captured with the absence of the middle and lower portions of the rankings. In the complete data, egos and their highly ranked alters tend to agree more broadly across the full ranking, which reduces local nonconformity. When only the top five rankings are observed, this additional agreement is no longer visible to the model, leading to consistently higher estimates of local nonconformity, once individuals have established who they consider to be their close friends as social circles form. While this is important to keep in mind when interpreting local nonconformity, the discrepancies in parameter estimates are small enough to indicate that the proposal method remains robust to missingness, even for this statistic. 
\hfill \break \hfill \break
Interestingly, when we fit the MLE on a modified dataset that excludes the top-five rankings, the trend is reversed. In this case, the parameter estimates for the partial data MLE are higher than those of the complete data MLE during the first six weeks, before converging to similar values in later weeks. This supports the idea that local nonconformity is not captured by the absence of the middle and lower portions of the rankings. 
\newpage
\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{Benchmarks/coef_trajectories_localandglobal.png}
\caption{Parameter estimates over time for local+global nonconformity, fitted on data where the top 5 rankings for each ego is missing.}
\end{figure}
\subsection{Time Efficiency of \texttt{AdjacentAlterSwap} compared to \texttt{AlterSwap}}
It is also important to compare the computational performance of the two proposal mechanisms on complete orderings. Fitting an ERGM to the full \citet{Newcomb1961-yh} dataset for the key statistics of deference, global nonconformity, and combined local–global nonconformity using the current \texttt{ergm.rank} implementation with the \texttt{AlterSwap} proposal requires approximately 2229 seconds. In contrast, using the revised implementation, incorporating the new auxiliary structure together with the \texttt{AdjacentAlterSwap} proposal, reduces the total computation time to roughly 475 seconds. Interestingly, using \texttt{AlterSwap} but using the revised implementation for the calculations of the key statistics takes approximately 257 seconds. This indicates that \texttt{AlterSwap} is inherently more efficient than \texttt{AdjacentAlterSwap}, although it is limited to complete rankings. 
\hfill \break \hfill \break
This is possibly due to the fact that \texttt{AdjacentAlterSwap} performs additional lookups in the auxiliary structure and enforces constraint checks for each proposed toggle, whereas \texttt{AlterSwap} relies on simple random selection and minimal computation, making it inherently faster for complete orderings. Importantly, \texttt{AlterSwap} cannot be applied to partial orderings, as it assumes all rankings are well-defined, with no missing or tied entries. Nevertheless, these results demonstrate that our proposed implementation of the up-down auxiliary structure substantially improves computational efficiency. For future work, we could explore different model parameters or benchmark performance for a given sample size, and extract statistics to estimate the effective sample size per second of runtime.
\subsection{Robustness of the Proposal Method to Partial Rankings}
Overall, the results from fitting MLEs to the \citet{Newcomb1961-yh} dataset show that little information is lost when restricting the data to partial rankings, as the parameter estimates remain close to those obtained from the complete rankings. These findings indicate that the proposed auxiliary structure, along with the modifications to the MCMC sampling algorithm, exhibits satisfactory robustness to missingness. These findings give confidence that the modified \texttt{ergm.rank} infrastructure can be applied to real-world datasets with genuine missing entries, while still yielding reliable and interpretable estimates. 
\chapter{Applying \texttt{ergm.rank} to Incomplete Real-World Data}
Having demonstrated that the proposed implementation of \texttt{ergm.rank} both improves computational efficiency and remains robust to missing data when applied to partially ranked datasets, we now turn to its application on real-world, incomplete data. 
\section{The Sampson Dataset}
The Sampson Monastery dataset \citep{Sa68n} is included in the \texttt{ergm} package. It describes the social relations among a group of men who are preparing to join a monastic order. The dataset records four distinct types of relations: esteem, liking, influence, and praise, and has separate matrices capturing both positive and negative ties for each relation. In this study, we focus on the liking relation. The Sampson dataset for the liking relation consists of six networks: \texttt{samplk1}, \texttt{samplk2}, \texttt{samplk3}, \texttt{sampdlk1}, \texttt{sampdlk2} and \texttt{sampdlk3}, where they represent three time points for liking and three time points for disliking. 
\hfill \break \hfill \break
These three time points were in the period during which a new cohort had entered the monastery near the end of the study but before the major conflict began, which resulted in the expulsion of four monks. \citet{Sa68n} divided the novices into four groups: Young Turks, Loyal Opposition, Outcasts, and an interstitial group. The Loyal Opposition consists of the novices who entered the monastery first, and the Young Turks arrived later. The latter questioned practices in the monastery, which the former defended. The who novices did not take sides in this debate were labeled 'interstitial'. The Outcasts are novices who were not accepted in the group. 
\hfill \break \hfill \break
Each member of the monastery was asked to rank only his top three choices for both relations, with the rest of the rankings being unknown. Most of the data were collected retrospectively, after the conflict had occurred, which may reduce their reliability. In contrast, the general consensus is that the liking data was collected contemporaneously, making them the primary focus of this study. This is precisely the type of dataset that the previous implementation of \texttt{ergm.rank} was unable to accommodate for. With the updated infrastructure, we can now fit an MLE to the missing rankings, allowing us to learn about the underlying preference structure, which we previously could not. The main motivation of fitting on this dataset is to see whether the observed rankings from these relations could have provided early indications of this conflict. 
\section{Implementation}
Similarly to the \citet{Newcomb1961-yh} dataset, a script was written to use the auxiliary structure in the \texttt{ergm.rank} to extract parameter estimates from key model statistics.
\subsection{Model Fitting}
The script takes each of the six networks and fills in the missing rankings based on the observed values, producing an initial network with a complete ordering. It then estimates the model parameters (MLE) for each network, while constraining the fit to the rankings that were actually observed, using \texttt{AdjacentAlterSwap}, storing the fitted MLEs for each network in a list. Currently, the initial parameter estimates are set to zero. A potential extension would be to first fit a model using zero starting values, and then use the resulting parameter estimates as  starting points for a second fit. However, this dramatically increases computational time, as random or uninformed starting values generally leads to slower convergence and longer MCMC burn-in periods. As a result, this approach was not feasible within the constraints of this project.
\subsection{Evaluation Metrics}
The same utility functions from the benchmarking script were used to extract the key model statistics, computing and storing:
\hfill \break
\begin{itemize}
    \item[$\bullet$] Coefficients: $\texttt{(coef())}$
    \item[$\bullet$] Standard errors: $\texttt{(sqrt(diag(vcov())))}$
    \item[$\bullet$] Log-likelihood at the MLE: $\texttt{(logLik())}$
\end{itemize}
\vspace{0.5em}
\subsection{Output}
The script generates visual comparisons of the evaluation metrics across the three time points for both the liking and disliking relations, allowing us to analyze how deference, global nonconformity, and local/global nonconformity changed over the study period.
\section{Computational Results and Analysis of \citet{Sa68n}}
\subsection{Liking Relation Analysis}
\subsubsection{Deference}
We observe that across the three time points, the estimated deference parameter for the Sampson liking relation stays quite negative at approximately -0.5, before dropping slightly to -0.6 in Time Point 2. In the context of the \citet{Sa68n} dataset, this is consistent with the arrival of the new cohort, the Young Turks, likely during Time Point 2. This timing is suggested by the survey questions in Sampson’s dissertation \citep{Sa68n}, which instruct respondents to skip Question 1 if they joined after ``[MONTH X]". By Time Point 3, groups had formed, meaning members may have shown greater deference within their respective groups, which likely explains the slight increase in the parameter estimate. However, even accounting for the standard error, the parameter estimates for deference are significantly negative and reflect tension and a general lack of reciprocal respect in the monastery, which likely contributed to the eventual conflict.
\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{Sampson/likeness_statistics.png}
\caption{Parameter estimates over time for deference, global nonconformity and local+global nonconformity for the likeness relation, where error bars indicate $\pm$1 standard error.}
\end{figure}
\hfill \break
\subsubsection{Nonconformity}
Global nonconformity rises over the three time points, indicating that individuals increasingly diverged from the dominant ranking patterns in the community. This is likely because early on, before the arrival of the Young Turks, the Loyal Opposition formed a relatively cohesive core. As new groups emerged when the new cohort arrived at around Time Point 2, ranking behaviour became more fragmented, which is reflected in the growing nonconformity parameter. However, the parameter estimates for global nonconformity are not statistically significant, and are not indicative of the dynamics leading to the monastery’s breakup. It is highly possible that global nonconformity was 0 over the entire time period, where the small fluctuations across time could possibly be due to information loss from observing only the top three rankings for each monk. It is therefore more meaningful to focus on nonconformity when the local component is included. 
\hfill \break \hfill \break
Local nonconformity reflects how individuals diverge specifically from those they rank highly, which offers nuance that global measures cannot capture, especially during periods of social change. Figure 6.1 shows that local/global nonconformity starts near 0 and dramatically drops to around -0.04 across both of the next two time points. Similarly to global nonconformity, local nonconformity was likely near 0 initially, as the Loyal Opposition comprised most members, leading to mutual respect among novices. After the arrival of the Young Turks, we see that discrepancies emerge, as individuals increasingly align their rankings with those they rank highly. This likely reflects the formation of these groups, as initiates conform more closely to the preferences of their in-group members, who be ranked highly compared to members who are outside of their group, who they would tend to rank lower. These parameter estimates for global and local nonconformity highlight the emerging divide between groups at the monastery, tensions that likely contributed to its eventual breakup.
\subsubsection{Insights from the Liking Network}
Evidently, The parameter estimates of the liking relation reflect the divide which split the novices into groups as the Young Turks arrived in Time Point 2. Most notably for deference and local/global nonconformity, the parameter estimates exhibit early signs of the lack of respect between novices outside of their respective groups, the tension of which likely came to a head at a later time. Overall, the implemented \texttt{ergm.rank} infrastructure successfully fit an MLE to the partially observed \citet{Sa68n} rankings, yielding results that are consistent with the known context and narrative of events at the monastery.
\subsection{Disliking Relation Analysis}
Unfortunately, attempts to fit ERGMs to the three disliking networks (\texttt{sampdlk1}, \texttt{sampdlk2}, \texttt{sampdlk3}) were less successful. While \texttt{sampdlk1} converged to a reasonable MLE, \texttt{sampdlk2} and \texttt{sampdlk3} had extremely long run times and did not reach convergence within feasible computational limits. This issue underscores the challenges faced when fitting MLEs to sparse partial rankings. When so little information is available, parameter estimation is unstable and is prohibitively slow to converge. 
\hfill \break \hfill \break
Since the disliking relations were collected retrospectively, after the conflict had already unfolded, it is likely that these rankings were less reliable compared to the liking data. Retrospective recall, especially for negative relations, tends to introduce noise, resulting in less coherent structural patterns for the ERGMs to capture. As a result, the ERGMs for disliking relations lacked consistent structural patterns for parameter estimation, yielding a poorfly defined likelihood and preventing the algorithm from converging to an MLE. Future works could look into improving the infrastructure to successfully fit these datasets, or simply more powerful hardware to reduce run times. We can, however, examine the results from fitting \texttt{sampdlk1} and compare them to the corresponding liking network at the same time point, \texttt{samplk1}.
\hfill \break \hfill \break
\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{Sampson/dislikeness_statistics.png}
\caption{Parameter estimates over time for deference, global nonconformity and local+global nonconformity for the dislikeness relation only for Time Point 1 due to issues when fitting the MLE.}
\end{figure} 
\hfill \break \hfill \break
Interestingly, skibid
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\bibliographystyle{agsm}
\bibliography{MyRefs}




\end{document}





